{
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'animal-detection-small-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F37898%2F57718%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240401%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240401T141102Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3fb75911db301ed36252a0cd5645226a6c81b6b9b99bfd4e928613bfba2ef4ab2141795c3348b5c003c2b72cc940a8b04538555e73265dcb599cc7a1367c52879afa49972634fc0ec9b44076c1f2184deba23ed158b3036ed718a8d8200e1daf0020a98cd424b22680be6c45cba85acaef9c1dddf93607af4fbf67bd86c8e2b2fe5a49e330949b6dc022c1367b0203abee8a848f37beda132a16a5139397934ef671ea7216cd708c4e4185b03bf740b31cdeaf63350e7bd9518f85e8618a430d8ecc34acaf10474e545d9ce64ed2b84f89b037e0f2db0ef0fbb970986304b1404709fa24f23225fb885881c57a5928ac1e57702e3ecdec8e5850135de5d56d5b,animal-classification:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F616920%2F1102439%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240401%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240401T141102Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dd4a099786465bb39c38d4daf5bdc3f6698532c8a0b6d51a8d197a0eb3e9ef5a474f90c3d37e6c9c9ae278d5d3810813f48a245123ef670ed966bb114e6cf120cdb1fbb6c6e89e4efedeab5a54c18b75a18b64acdad7bebeda07157e3fed646d870a133edaa7e815fab3e4e4c397dd2091b60a66b63cfb3da43ae5803582489b381804a2284c0898cc6c8f0d1ab381e01d3bfff644d010c3b87e0c17c02b11859fa5957ba43862f5f93c7543ae527f81cf63a44898e3e881149ca66565a74604d2b4748724bac38b1dd351581a69c4cfcbe8b5eceb8d930d01efe37c01818ac59370f169d02de8055cf7a1b9ecbbf1bff2bb41b051060ac032836cd996deec87f,african-wildlife:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F674157%2F1185810%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240401%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240401T141102Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dbeb365d12d7f56e230abdcfc331a9837b4dba8fe1978d7d0090d9f149d649ac9bd25c33890df99129c3ccba78dd817596ef17a4046aec8f04aaefe18efc1d6234cc03385ea71faa8d1b743444b2a48731fa74b4721bd484e738c66cb731f610001421cc87ccb38adc48f73619284ea0386e335d67155c203b0c579f982af6104dc664babbc8cdfc328f4ac76e27123379503e3ac43a7d6733d9d81b3a759fbe486846444b642d76407d36dd5ee67df9cf32b81f01627a95fde3132f247e8030dac2fa7fc838802316459c19a27cc84039aa805d5e0481f43cc62bda072ecfb3ee3a2c7878f222fcdfdb4586e2e754ca4cb554ac7a910768e7fe08a72a3e7e9e4,cheetahtigerwolf:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F731756%2F1270998%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240401%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240401T141102Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D17b311113139f260e0d7a80b96a0c14abc02fd70f4220276b83c31bf99cfdea52deca25fc829d4d60265f9dc56d99893d49cac9a302bbe9f337e9e3e44da932f73bb9d5c0eed5d14c1038f514f217ecd378dc31d090e4f2fe53def6ead697ceb3b14dd085073aec1fc2e32c54ed17b573e7d127e5c50352146f1658dad800ab330f8c9d91d7f0b3611da372cb41b46400c46f172832d8905f691c3990730abe81ea809b116f3a0280afb8f7b4a3376523f1248605863717a6db2505085ef44ca678fe051ec727b606ce8d9e10686c5a97fd03fe7ae8e0c09b0662862e5252fc6dccf204483428e3da72dfe2e428205d606da54f9b7497bdc501c94cbdf22b304'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "ywExCfC8_9a8"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "V65tig40_9a_"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 1: Importing Libraries"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "r02EuxCL_9bB"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "from platform import python_version\n",
        "\n",
        "print('Python version:', python_version())\n",
        "print('Numpy version:', np.__version__)\n",
        "print('Seaborn version:', sns.__version__)\n",
        "from distutils.dir_util import copy_tree\n",
        "import tensorflow as tf\n",
        "print('tensorflow version: ',tf.__version__)\n",
        "print('keras version:', keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "zkfO5Na7_9bB"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout\n",
        "from keras_preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t25PuJ5g_9bC"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 2: Dataset Creation"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "UtISj8uF_9bC"
      },
      "cell_type": "code",
      "source": [
        "#created data set using console\n",
        "source='../input/african-wildlife/'\n",
        "target='./train_data/'\n",
        "shutil.copytree(source, target)\n",
        "os.mkdir('test_data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "IPKM5veE_9bD"
      },
      "cell_type": "code",
      "source": [
        "# remove unwanted data and create same classed for test_data\n",
        "\n",
        "path=\"./train_data/\"\n",
        "for file in os.listdir(path):\n",
        "    for image in os.listdir(path+file+'/'):\n",
        "        if '.jpg' not in image:\n",
        "            os.remove(path+file+'/'+image)\n",
        "    os.mkdir('./test_data/'+file)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "CgXbB5wV_9bD"
      },
      "cell_type": "code",
      "source": [
        "# create test_data by taking 25% images from data\n",
        "\n",
        "total_train_images,total_test_images,total_train_classes,total_test_classes=0,0,0,0\n",
        "path=\"./train_data/\"\n",
        "for file in os.listdir(path):\n",
        "    total_train_classes+=1\n",
        "    total_images=len(os.listdir(path+file+\"/\"))\n",
        "    test_image_count=(25/100)*total_images #25% for test and 75% for train\n",
        "    for i in range(math.ceil(test_image_count)):\n",
        "        img=random.choice(os.listdir(path+file+'/'))\n",
        "        shutil.move(path+file+'/'+img,'./test_data/'+file+'/')\n",
        "        #print(img)\n",
        "    print(file,total_images,math.ceil(test_image_count))\n",
        "    total_train_images+=(total_images-math.ceil(test_image_count))\n",
        "    #print(file,math.ceil(test_image_count))\n",
        "print(\"total train images are : \",total_train_images,\" and total train classes are : \",total_train_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xhHkWak1_9bE"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 3: Model Creation"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "G1DPDgqO_9bE"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "7Mg_wcH3_9bF"
      },
      "cell_type": "code",
      "source": [
        "#inputlayer : apply filters\n",
        "model.add(Convolution2D(filters=32,\n",
        "                        kernel_size=(3,3),\n",
        "                        strides=(1,1),\n",
        "                        padding='same',\n",
        "                        activation='relu',\n",
        "                   input_shape=(32, 32, 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "s-_yfxz0_9bF"
      },
      "cell_type": "code",
      "source": [
        "# pooling layer where we are doing maxpooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "iYMi1zUT_9bF"
      },
      "cell_type": "code",
      "source": [
        "#adding one more convolution layer for better model\n",
        "model.add(Convolution2D(filters=32,\n",
        "                        kernel_size=(3,3),\n",
        "                        strides=(1,1),\n",
        "                        padding='same',\n",
        "                        activation='relu'\n",
        "                      ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "eBgInJFJ_9bG"
      },
      "cell_type": "code",
      "source": [
        "#adding one more Pooling layer for better model\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "K2YhKCVo_9bG"
      },
      "cell_type": "code",
      "source": [
        "#dropout regularlization\n",
        "model.add(Dropout(0.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "nvR5Ocj2_9bG"
      },
      "cell_type": "code",
      "source": [
        "#layer in which we are converting 2d/3d image to 1d image i.e flattening\n",
        "model.add(Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "X5Pe2_b4_9bG"
      },
      "cell_type": "code",
      "source": [
        "# layer: appling relu to give positive output from here our hidden layerrs starts\n",
        "model.add(Dense(units=20, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "xXQ8cUpW_9bH"
      },
      "cell_type": "code",
      "source": [
        "#dropout regularlization\n",
        "model.add(Dropout(0.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "JBtoOBPm_9bH"
      },
      "cell_type": "code",
      "source": [
        "# output layer : Since we have to do multi-class classification so we'll apply softmax activation function\n",
        "# we have 4 classes of animals so output layer would have that many neurons.\n",
        "model.add(Dense(units=4, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "zWjOHD3A_9bH"
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "sw8hrFdd_9bH"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "17rE4eqF_9bH"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 4: Image Augmentation"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "-L5PurCv_9bH"
      },
      "cell_type": "code",
      "source": [
        "#url : https://keras.io/api/preprocessing/image/\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "        './train_data/',\n",
        "        target_size=(32,32),\n",
        "        color_mode=\"grayscale\",\n",
        "        batch_size=64,\n",
        "        class_mode='categorical')\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        './test_data/',\n",
        "        target_size=(32,32),\n",
        "        color_mode=\"grayscale\",\n",
        "        batch_size=64,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "lmkfpH4G_9bH"
      },
      "cell_type": "code",
      "source": [
        "training_set.class_indices # to see classes of our dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "bSF0BFen_9bH"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XZ9XDIHU_9bI"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 5: Model Training"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "KbgOOSBY_9bI"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "        training_set,\n",
        "        steps_per_epoch=(1125/64),\n",
        "        epochs=100,\n",
        "        validation_data=test_set,\n",
        "        validation_steps=(376/64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "PuZdngqS_9bI"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vdTDsGPL_9bI"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 6: Accuracy"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "NPn7Ou9w_9bI"
      },
      "cell_type": "code",
      "source": [
        "#Graphing our training and validation\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_ToAdLK6_9bI"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "S7pOKjWG_9bI"
      },
      "cell_type": "code",
      "source": [
        "#model.save(\"simple_animal_classification_model.h5\")#save model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "L7XcIbkL_9bI"
      },
      "cell_type": "code",
      "source": [
        "#from keras.models import load_model\n",
        "#model=load_model(\"simple_animal_classification_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eq38YPsn_9bJ"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 7: Testing"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Wh4Sxp72_9bJ"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "test_image = image.load_img(\"../input/african-wildlife/zebra/001.jpg\",target_size=(32,32),color_mode='grayscale')\n",
        "test_image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "JMHqoowP_9bJ"
      },
      "cell_type": "code",
      "source": [
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image,axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "v8gDbEBH_9bJ"
      },
      "cell_type": "code",
      "source": [
        "result = model.predict(test_image)\n",
        "\n",
        "my_dict=training_set.class_indices\n",
        "def get_key(val):\n",
        "    for key, value in my_dict.items():\n",
        "         if val == value:\n",
        "             return key\n",
        "\n",
        "    return \"key doesn't exist\"\n",
        "\n",
        "pred=list(result[0])\n",
        "for i in range(len(pred)):\n",
        "    if pred[i]!=0:\n",
        "        print(get_key(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "K-FylDxy_9bJ"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "x7FV4b5U_9bJ"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Animal Species Detection Project",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}